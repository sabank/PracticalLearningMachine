---
title: "Prediction Machine Learning"
author: "Sabank"
date: "December 27, 2015"
output:
  html_document:
    keep_md: yes
  pdf_document: default
---

#### Synopsis:
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

The following analysis uses a random forest-based prediction algorithm to accomplish this task. This type of algorithm is usually suited for providing categorical outputs. With an estimated out-of-sample error of 0.14%, the model achieves an accuracy of 99.86% in predicting the quality of execution of a particular activity.

#### 1. Introduction
Six participants were asked to perform one set of 10 repetitions of barbell lifts in five different fashions, categorized as classes A, B, C, D and E. Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

In this project, our goal was to use data from accelerometers on the bell, forearm, arm, and dumbell of the participants to build a prediction algorithm that takes these sensor readings and, given both a training and test dataset, correctly predicts the corresponding class (A to E).

More information on the whole dataset is available here: Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. [Qualitative Activity Recognition of Weight Lifting Exercises](http://groupware.les.inf.puc-rio.br/har). Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13). Stuttgart, Germany: ACM SIGCHI, 2013.

#### 2. Data Preparation
##### 2.1 Setting analysis environment
```{r, echo=TRUE,results='hold',warning=FALSE}
set.seed(987)
library(caret)
library(randomForest)
library(e1071)
```

##### 2.2 Importing data
```{r, echo=TRUE}
# note: change 'https' for 'http' for calling 'read.csv(url())'
train_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

# initial inspection of files allows to set read.csv command as follow
ptrain <- read.csv(url(train_url),header=TRUE,sep =",",na.strings=c("NA","#DIV/0!",""))
ptest <- read.csv(url(test_url),header=TRUE,sep =",",na.strings=c("NA","#DIV/0!",""))

dim(ptrain)
```

##### 2.3 Processing data
```{r, echo=TRUE,results='hide'}
# considering dimensions of training set, let's subset training set to create a validation set for estimating the out-of-sample error, and let's partition this set with p=3/4
inTrain <- createDataPartition(y=ptrain$classe,p=0.75,list=FALSE)
ptrain_train <- ptrain[inTrain,]
ptrain_valid <- ptrain[-inTrain,]

# exploratory analysis allows to select relevant variables as follow
# remove variables that are not sensor readings
ptrain_train <- ptrain_train[,-(1:5)]
ptrain_valid <- ptrain_valid[,-(1:5)]

# remove variables with nearly zero variance
nzv <- nearZeroVar(ptrain_train)
ptrain_train <- ptrain_train[,-nzv]
ptrain_valid <- ptrain_valid[,-nzv]

# remove variables that are almost always NA
allNA <- sapply(ptrain_train,function(x) mean(is.na(x))) > 0.95
ptrain_train <- ptrain_train[,allNA==FALSE]
ptrain_valid <- ptrain_valid[,allNA==FALSE]
```

#### 3. Predictive Model Building
##### 3.1 Training the Predictor
```{r, echo=TRUE}
# use 3-fold cross-validation
fitControl <- trainControl(method="cv",number=3,verboseIter=FALSE)

# fit model on ptrain_train and print final model parameters
fit <- train(classe ~ .,data=ptrain_train,method="rf",trControl=fitControl)
fit$finalModel
```

##### 3.2 Evaluation
```{r,echo=TRUE}
# use model to predict 'classe' in ptrain_valid and print confusion matrix
evalpred <- predict(fit,newdata=ptrain_valid)
confusionMatrix(ptrain_valid$classe,evalpred)
```

##### 3.3 Retraining the Model
```{r,echo=TRUE}
# remove variables that are not sensor readings
ptrain <- ptrain[,-(1:5)]
ptest <- ptest[,-(1:5)]

# remove variables with nearly zero variance
nzv <- nearZeroVar(ptrain)
ptrain <- ptrain[,-nzv]
ptest <- ptest[,-nzv]

# remove variables that are almost always NA
allNA <- sapply(ptrain,function(x) mean(is.na(x))) > 0.95
ptrain <- ptrain[,allNA==FALSE]
ptest <- ptest[,allNA==FALSE]

# re-fit model on ptrain and print final model parameters
fitControl <- trainControl(method="cv",number=3,verboseIter=FALSE)
fit <- train(classe ~ .,data=ptrain,method="rf",trControl=fitControl)
fit$finalModel
```

#### 4. Application to 'Test' Set
##### 4.1 Predictions
```{r,echo=TRUE}
answers <- predict(fit,newdata=ptest)
answers
```

##### 4.2 File creation
``` {r,echo=TRUE,results='hold'}
# convert predictions to character vector
answers <- as.character(answers)
# create function to write predictions to files
pml_write_files <- function(x) {
    n <- length(x)
    for(i in 1:n) {
        filename <- paste0("problem_id_", i, ".txt")
        write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
    }
}
# create prediction files to submit
pml_write_files(answers)
```

#### 5. Conclusion
The random forest-based model applied to the test set provides an accuracy of 99.86% with 3-fold cross-validation parameter, thus the predicted accuracy for the out-of-sample error is 0.14%. This is a first-hand excellent result, also an expected outcome provided the type of the algorithm chosen, that did not invite to assess another algorithm. Moreover, the application of this model on the 20 test cases resulted in 100% prediction accuracy.

#### 6. System Information
``` {r,echo=FALSE}
Sys.info()[1:2]
R.version.string
```